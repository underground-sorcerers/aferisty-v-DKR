{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "Y8utaGr-z9-s",
    "outputId": "f3882f7a-dece-489e-a1bb-53bd171e6940",
    "ExecuteTime": {
     "end_time": "2024-11-29T17:49:31.637149Z",
     "start_time": "2024-11-29T17:49:31.632285Z"
    }
   },
   "source": "# !pip install git+https://github.com/pyg-team/pytorch_geometric.git",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import from_networkx\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "id": "umZifMrxz_mF",
    "ExecuteTime": {
     "end_time": "2024-11-29T17:49:31.663174Z",
     "start_time": "2024-11-29T17:49:31.657883Z"
    }
   },
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "# Load the tabular dataset\n",
    "df = pd.read_csv(\"dataset_files/credit_card_transactions-ibm_v2.csv\").sample(n=100000, random_state=42)\n",
    "df[\"card_id\"] = df[\"User\"].astype(str) + \"_\" + df[\"Card\"].astype(str)\n",
    "df[\"Amount\"]=df[\"Amount\"].str.replace(\"$\",\"\").astype(float)\n",
    "df[\"Hour\"] = df[\"Time\"].str [0:2]\n",
    "df[\"Minute\"] = df[\"Time\"].str [3:5]\n",
    "df = df.drop([\"Time\",\"User\",\"Card\"],axis=1)\n",
    "df[\"Errors?\"]= df[\"Errors?\"].fillna(\"No error\")\n",
    "df = df.drop(columns=[\"Merchant State\",\"Zip\"],axis=1)\n",
    "df[\"Is Fraud?\"] = df[\"Is Fraud?\"].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "df[\"Merchant City\"]=LabelEncoder().fit_transform(df[\"Merchant City\"])\n",
    "df[\"Use Chip\"]=LabelEncoder().fit_transform(df[\"Use Chip\"])\n",
    "df[\"Errors?\"]=LabelEncoder().fit_transform(df[\"Errors?\"])"
   ],
   "metadata": {
    "id": "5BWHY6m50F0d",
    "ExecuteTime": {
     "end_time": "2024-11-29T17:51:17.576132Z",
     "start_time": "2024-11-29T17:49:31.718516Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "# fraudulent = df[df[\"Is Fraud?\"] == 1]\n",
    "# non_fraudulent = df[df[\"Is Fraud?\"] == 0]\n",
    "\n",
    "# print(f\"Number of fraudulent transactions: {len(fraudulent)}\")\n",
    "# print(f\"Number of non-fraudulent transactions: {len(non_fraudulent)}\")\n",
    "\n",
    "# desired_ratio = 1  # Ratio of non-fraud to fraud (e.g., 1 means 1:1 balance)\n",
    "# non_fraud_sample_size = len(fraudulent) * desired_ratio\n",
    "\n",
    "# non_fraudulent_sampled = non_fraudulent.sample(n=non_fraud_sample_size, random_state=42)\n",
    "\n",
    "# balanced_df = pd.concat([fraudulent, non_fraudulent_sampled])\n",
    "# balanced_df = balanced_df.sample(frac=1, random_state=42)\n",
    "\n",
    "# print(f\"Balanced dataset size: {len(balanced_df)}\")\n",
    "# print(balanced_df[\"Is Fraud?\"].value_counts())\n",
    "# df = balanced_df.copy()"
   ],
   "metadata": {
    "id": "uoTD3e71jF5V",
    "ExecuteTime": {
     "end_time": "2024-11-29T17:51:17.647675Z",
     "start_time": "2024-11-29T17:51:17.642620Z"
    }
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "class GraphConstruction:\n",
    "    def __init__(self, nodes, edges, features=None):\n",
    "        self.g_nx = nx.DiGraph()\n",
    "        self.add_nodes(nodes)\n",
    "        self.add_edges(edges)\n",
    "        self.node_features = features if features is not None else {}\n",
    "\n",
    "    def add_nodes(self, nodes):\n",
    "        for ntype, nodelist in nodes.items():\n",
    "            for node in nodelist:\n",
    "                self.g_nx.add_node(node, ntype=ntype)\n",
    "\n",
    "    def add_edges(self, edges):\n",
    "        for edge in edges:\n",
    "            self.g_nx.add_edges_from(edge)\n",
    "\n",
    "    def to_pyg_data(self):\n",
    "        data = HeteroData()\n",
    "        node_id_mapping = {ntype: [] for ntype in set(nx.get_node_attributes(self.g_nx, 'ntype').values())}\n",
    "\n",
    "        print(\"Processing nodes...\")\n",
    "        for node, ndata in tqdm(self.g_nx.nodes(data=True), desc=\"Nodes\"):\n",
    "            ntype = ndata['ntype']\n",
    "            if 'x' not in data[ntype]:\n",
    "                data[ntype].x = []\n",
    "            node_id_mapping[ntype].append(node)\n",
    "            if self.node_features and ntype in self.node_features:\n",
    "                if node in self.node_features[ntype].index:\n",
    "                    features = self.node_features[ntype].loc[node].values\n",
    "                    features = [float(f) if isinstance(f, (int, float)) else 0.0 for f in features]\n",
    "                    data[ntype].x.append(features)\n",
    "                else:\n",
    "                    data[ntype].x.append([0.0] * self.node_features[ntype].shape[1])\n",
    "\n",
    "        print(\"Converting node features to tensors...\")\n",
    "        for ntype in tqdm(data.node_types, desc=\"Node Types\"):\n",
    "            data[ntype].x = torch.tensor(data[ntype].x, dtype=torch.float)\n",
    "\n",
    "        print(\"Processing edges...\")\n",
    "        for u, v in tqdm(self.g_nx.edges(), desc=\"Edges\"):\n",
    "            u_type = self.g_nx.nodes[u]['ntype']\n",
    "            v_type = self.g_nx.nodes[v]['ntype']\n",
    "            edge_type = (u_type, 'to', v_type)\n",
    "            if edge_type not in data.edge_types:\n",
    "                data[edge_type].edge_index = [[], []]\n",
    "            if u in node_id_mapping[u_type] and v in node_id_mapping[v_type]:\n",
    "                u_index = node_id_mapping[u_type].index(u)\n",
    "                v_index = node_id_mapping[v_type].index(v)\n",
    "                data[edge_type].edge_index[0].append(u_index)\n",
    "                data[edge_type].edge_index[1].append(v_index)\n",
    "\n",
    "        print(\"Converting edge indices to tensors...\")\n",
    "        for edge_type in tqdm(data.edge_types, desc=\"Edge Types\"):\n",
    "            edge_index = data[edge_type].edge_index\n",
    "            data[edge_type].edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
    "\n",
    "        return data"
   ],
   "metadata": {
    "id": "G0F6rtsv1ItR",
    "ExecuteTime": {
     "end_time": "2024-11-29T17:51:17.856784Z",
     "start_time": "2024-11-29T17:51:17.830036Z"
    }
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
    "        self.linear = torch.nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, edge_index)\n",
    "            x = F.elu(x)\n",
    "        x = self.convs[-1](x, edge_index)\n",
    "        x = self.linear(x)\n",
    "        # return torch.log_softmax(x, dim=-1)\n",
    "        return x"
   ],
   "metadata": {
    "id": "bEFKhytQ1SPo",
    "ExecuteTime": {
     "end_time": "2024-11-29T17:51:17.941748Z",
     "start_time": "2024-11-29T17:51:17.936660Z"
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "# Encode categorical features\n",
    "le_card = LabelEncoder()\n",
    "le_merchant = LabelEncoder()\n",
    "df['card_id_enc'] = le_card.fit_transform(df['card_id'])\n",
    "df['merchant_enc'] = le_merchant.fit_transform(df['Merchant Name'])\n",
    "\n",
    "# Balancing the dataset without resetting the index\n",
    "fraudulent = df[df[\"Is Fraud?\"] == 1]\n",
    "non_fraudulent = df[df[\"Is Fraud?\"] == 0]\n",
    "\n",
    "desired_ratio = 1  # 2:1 balance\n",
    "non_fraud_sample_size = round(len(fraudulent) * desired_ratio)\n",
    "non_fraudulent_sampled = non_fraudulent.sample(n=non_fraud_sample_size, random_state=42)\n",
    "\n",
    "balanced_df = pd.concat([fraudulent, non_fraudulent_sampled])\n",
    "balanced_df = balanced_df.sample(frac=1, random_state=42)  # Do not reset index\n",
    "print(f\"Balanced dataset size: {len(balanced_df)}\")\n",
    "print(balanced_df[\"Is Fraud?\"].value_counts())\n",
    "\n",
    "df = balanced_df.copy()\n",
    "# Transform labels using the same encoders\n",
    "df['card_id_enc'] = le_card.transform(df['card_id'])\n",
    "df['merchant_enc'] = le_merchant.transform(df['Merchant Name'])\n",
    "\n",
    "# Split data into training and inductive sets\n",
    "cutoff = round(0.7 * len(df))\n",
    "train_data = df.iloc[:cutoff]\n",
    "inductive_data = df.iloc[cutoff:]\n",
    "\n",
    "# Prepare node features\n",
    "transaction_features = train_data.drop(columns=['card_id', 'Merchant Name', 'Is Fraud?', 'card_id_enc', 'merchant_enc'])\n",
    "transaction_features.index = train_data.index\n",
    "client_features = pd.DataFrame(index=train_data['card_id_enc'].unique())\n",
    "merchant_features = pd.DataFrame(index=train_data['merchant_enc'].unique())\n",
    "\n",
    "train_mask = torch.zeros(len(df), dtype=torch.bool)\n",
    "val_mask = torch.zeros(len(df), dtype=torch.bool)\n",
    "\n",
    "train_mask[:cutoff] = True  # Training nodes\n",
    "val_mask[cutoff:] = True\n",
    "\n",
    "# Create nodes and edges\n",
    "nodes = {\n",
    "    'client': df['card_id_enc'].unique(),\n",
    "    'merchant': df['merchant_enc'].unique(),\n",
    "    'transaction': df.index\n",
    "}\n",
    "edges = [\n",
    "    list(zip(df['card_id_enc'], df.index)),\n",
    "    list(zip(df.index, df['merchant_enc']))\n",
    "]\n",
    "features = {\n",
    "    'transaction': df.drop(columns=['card_id', 'Merchant Name', 'Is Fraud?', 'card_id_enc', 'merchant_enc']),\n",
    "    'client': pd.DataFrame(index=df['card_id_enc'].unique()),\n",
    "    'merchant': pd.DataFrame(index=df['merchant_enc'].unique())\n",
    "}\n",
    "\n",
    "# Build graph\n",
    "graph = GraphConstruction(nodes, edges, features)\n",
    "data = graph.to_pyg_data()\n",
    "\n",
    "data['transaction'].train_mask = train_mask\n",
    "data['transaction'].val_mask = val_mask\n",
    "data['transaction'].y = torch.tensor(df['Is Fraud?'].values, dtype=torch.long)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U5TjX5hi1TeJ",
    "outputId": "cb3e5100-8d9d-4127-bd9f-fc23c3b97da7",
    "ExecuteTime": {
     "end_time": "2024-11-29T17:51:18.264800Z",
     "start_time": "2024-11-29T17:51:18.050805Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced dataset size: 234\n",
      "Is Fraud?\n",
      "1    117\n",
      "0    117\n",
      "Name: count, dtype: int64\n",
      "Processing nodes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nodes: 100%|██████████| 602/602 [00:00<00:00, 16604.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting node features to tensors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Node Types: 100%|██████████| 3/3 [00:00<00:00, 937.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Edges: 100%|██████████| 468/468 [00:00<00:00, 113852.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting edge indices to tensors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Edge Types: 100%|██████████| 3/3 [00:00<00:00, 9709.04it/s]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "# Define model\n",
    "in_channels = transaction_features.shape[1]\n",
    "hidden_channels = 16\n",
    "out_channels = 2  # Binary classification\n",
    "num_layers = 4\n",
    "model = GraphSAGE(in_channels, hidden_channels, out_channels, num_layers)\n",
    "\n",
    "# Training setup\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# Training loop\n",
    "model.train()\n",
    "target_labels = torch.tensor(train_data['Is Fraud?'].values, dtype=torch.long)  # Convert to tensor\n",
    "\n",
    "for epoch in range(10000):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    out = model(data['transaction'].x, data[('transaction', 'to', 'merchant')].edge_index)\n",
    "    loss = criterion(out[data['transaction'].train_mask], data['transaction'].y[data['transaction'].train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jRNw-Hrn491X",
    "outputId": "cb620438-15a7-41c8-84df-a1007fb3dba4",
    "ExecuteTime": {
     "end_time": "2024-11-29T17:59:11.230678Z",
     "start_time": "2024-11-29T17:58:45.105632Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6970428824424744\n",
      "Epoch 10, Loss: 0.6919825077056885\n",
      "Epoch 20, Loss: 0.687341034412384\n",
      "Epoch 30, Loss: 0.6831300258636475\n",
      "Epoch 40, Loss: 0.6793301105499268\n",
      "Epoch 50, Loss: 0.6759001612663269\n",
      "Epoch 60, Loss: 0.6727949976921082\n",
      "Epoch 70, Loss: 0.6699753999710083\n",
      "Epoch 80, Loss: 0.6674044132232666\n",
      "Epoch 90, Loss: 0.6650488972663879\n",
      "Epoch 100, Loss: 0.6628803014755249\n",
      "Epoch 110, Loss: 0.6608742475509644\n",
      "Epoch 120, Loss: 0.6590107679367065\n",
      "Epoch 130, Loss: 0.6572735905647278\n",
      "Epoch 140, Loss: 0.6556549072265625\n",
      "Epoch 150, Loss: 0.6541447639465332\n",
      "Epoch 160, Loss: 0.6527310609817505\n",
      "Epoch 170, Loss: 0.6514045000076294\n",
      "Epoch 180, Loss: 0.6501570343971252\n",
      "Epoch 190, Loss: 0.6489807367324829\n",
      "Epoch 200, Loss: 0.6478680372238159\n",
      "Epoch 210, Loss: 0.6468102931976318\n",
      "Epoch 220, Loss: 0.6457993388175964\n",
      "Epoch 230, Loss: 0.6448282599449158\n",
      "Epoch 240, Loss: 0.6438897252082825\n",
      "Epoch 250, Loss: 0.6429756283760071\n",
      "Epoch 260, Loss: 0.6420775055885315\n",
      "Epoch 270, Loss: 0.6411914229393005\n",
      "Epoch 280, Loss: 0.6403295993804932\n",
      "Epoch 290, Loss: 0.6394939422607422\n",
      "Epoch 300, Loss: 0.6386827826499939\n",
      "Epoch 310, Loss: 0.6378940939903259\n",
      "Epoch 320, Loss: 0.6371254920959473\n",
      "Epoch 330, Loss: 0.6363747715950012\n",
      "Epoch 340, Loss: 0.6356408596038818\n",
      "Epoch 350, Loss: 0.6349228024482727\n",
      "Epoch 360, Loss: 0.6342192888259888\n",
      "Epoch 370, Loss: 0.6335298418998718\n",
      "Epoch 380, Loss: 0.6328539252281189\n",
      "Epoch 390, Loss: 0.6321908831596375\n",
      "Epoch 400, Loss: 0.6315402984619141\n",
      "Epoch 410, Loss: 0.6309029459953308\n",
      "Epoch 420, Loss: 0.6302788257598877\n",
      "Epoch 430, Loss: 0.6296667456626892\n",
      "Epoch 440, Loss: 0.629065752029419\n",
      "Epoch 450, Loss: 0.6284752488136292\n",
      "Epoch 460, Loss: 0.6278944611549377\n",
      "Epoch 470, Loss: 0.6273232698440552\n",
      "Epoch 480, Loss: 0.6267608404159546\n",
      "Epoch 490, Loss: 0.6262068152427673\n",
      "Epoch 500, Loss: 0.6256615519523621\n",
      "Epoch 510, Loss: 0.6251266002655029\n",
      "Epoch 520, Loss: 0.6246019601821899\n",
      "Epoch 530, Loss: 0.6240866780281067\n",
      "Epoch 540, Loss: 0.6235795617103577\n",
      "Epoch 550, Loss: 0.623079776763916\n",
      "Epoch 560, Loss: 0.6225869059562683\n",
      "Epoch 570, Loss: 0.6221004128456116\n",
      "Epoch 580, Loss: 0.6216197609901428\n",
      "Epoch 590, Loss: 0.621144711971283\n",
      "Epoch 600, Loss: 0.6206748485565186\n",
      "Epoch 610, Loss: 0.6202098727226257\n",
      "Epoch 620, Loss: 0.619749903678894\n",
      "Epoch 630, Loss: 0.619297206401825\n",
      "Epoch 640, Loss: 0.6188518404960632\n",
      "Epoch 650, Loss: 0.618412971496582\n",
      "Epoch 660, Loss: 0.6179800629615784\n",
      "Epoch 670, Loss: 0.6175525188446045\n",
      "Epoch 680, Loss: 0.6171293258666992\n",
      "Epoch 690, Loss: 0.6167110204696655\n",
      "Epoch 700, Loss: 0.616297721862793\n",
      "Epoch 710, Loss: 0.6158890724182129\n",
      "Epoch 720, Loss: 0.6154847145080566\n",
      "Epoch 730, Loss: 0.615084171295166\n",
      "Epoch 740, Loss: 0.6146873235702515\n",
      "Epoch 750, Loss: 0.6142944097518921\n",
      "Epoch 760, Loss: 0.6139054894447327\n",
      "Epoch 770, Loss: 0.6135202050209045\n",
      "Epoch 780, Loss: 0.6131387948989868\n",
      "Epoch 790, Loss: 0.6127607822418213\n",
      "Epoch 800, Loss: 0.6123864650726318\n",
      "Epoch 810, Loss: 0.6120161414146423\n",
      "Epoch 820, Loss: 0.6116495132446289\n",
      "Epoch 830, Loss: 0.611286461353302\n",
      "Epoch 840, Loss: 0.6109263300895691\n",
      "Epoch 850, Loss: 0.610569179058075\n",
      "Epoch 860, Loss: 0.6102148294448853\n",
      "Epoch 870, Loss: 0.6098631620407104\n",
      "Epoch 880, Loss: 0.6095142960548401\n",
      "Epoch 890, Loss: 0.6091681122779846\n",
      "Epoch 900, Loss: 0.6088244318962097\n",
      "Epoch 910, Loss: 0.608483076095581\n",
      "Epoch 920, Loss: 0.6081438064575195\n",
      "Epoch 930, Loss: 0.607806384563446\n",
      "Epoch 940, Loss: 0.6074706315994263\n",
      "Epoch 950, Loss: 0.6071359515190125\n",
      "Epoch 960, Loss: 0.6068025231361389\n",
      "Epoch 970, Loss: 0.6064701676368713\n",
      "Epoch 980, Loss: 0.6061393618583679\n",
      "Epoch 990, Loss: 0.6058098673820496\n",
      "Epoch 1000, Loss: 0.6054816842079163\n",
      "Epoch 1010, Loss: 0.6051546335220337\n",
      "Epoch 1020, Loss: 0.6048285365104675\n",
      "Epoch 1030, Loss: 0.6045034527778625\n",
      "Epoch 1040, Loss: 0.6041788458824158\n",
      "Epoch 1050, Loss: 0.6038550138473511\n",
      "Epoch 1060, Loss: 0.6035315990447998\n",
      "Epoch 1070, Loss: 0.6032083630561829\n",
      "Epoch 1080, Loss: 0.6028854250907898\n",
      "Epoch 1090, Loss: 0.6025629639625549\n",
      "Epoch 1100, Loss: 0.6022412180900574\n",
      "Epoch 1110, Loss: 0.6019202470779419\n",
      "Epoch 1120, Loss: 0.6015999913215637\n",
      "Epoch 1130, Loss: 0.6012805104255676\n",
      "Epoch 1140, Loss: 0.6009618043899536\n",
      "Epoch 1150, Loss: 0.6006441116333008\n",
      "Epoch 1160, Loss: 0.6003268361091614\n",
      "Epoch 1170, Loss: 0.6000099778175354\n",
      "Epoch 1180, Loss: 0.5996935367584229\n",
      "Epoch 1190, Loss: 0.5993770360946655\n",
      "Epoch 1200, Loss: 0.599060595035553\n",
      "Epoch 1210, Loss: 0.5987439155578613\n",
      "Epoch 1220, Loss: 0.598426878452301\n",
      "Epoch 1230, Loss: 0.5981096625328064\n",
      "Epoch 1240, Loss: 0.597792387008667\n",
      "Epoch 1250, Loss: 0.5974745750427246\n",
      "Epoch 1260, Loss: 0.597156286239624\n",
      "Epoch 1270, Loss: 0.5968375205993652\n",
      "Epoch 1280, Loss: 0.5965180397033691\n",
      "Epoch 1290, Loss: 0.5961976051330566\n",
      "Epoch 1300, Loss: 0.5958766341209412\n",
      "Epoch 1310, Loss: 0.5955557227134705\n",
      "Epoch 1320, Loss: 0.5952351093292236\n",
      "Epoch 1330, Loss: 0.5949150919914246\n",
      "Epoch 1340, Loss: 0.5945960283279419\n",
      "Epoch 1350, Loss: 0.5942788124084473\n",
      "Epoch 1360, Loss: 0.5939636826515198\n",
      "Epoch 1370, Loss: 0.5936509370803833\n",
      "Epoch 1380, Loss: 0.5933405756950378\n",
      "Epoch 1390, Loss: 0.5930326581001282\n",
      "Epoch 1400, Loss: 0.5927270650863647\n",
      "Epoch 1410, Loss: 0.592424213886261\n",
      "Epoch 1420, Loss: 0.5921234488487244\n",
      "Epoch 1430, Loss: 0.591824471950531\n",
      "Epoch 1440, Loss: 0.5915270447731018\n",
      "Epoch 1450, Loss: 0.5912312865257263\n",
      "Epoch 1460, Loss: 0.5909374356269836\n",
      "Epoch 1470, Loss: 0.5906454920768738\n",
      "Epoch 1480, Loss: 0.590355634689331\n",
      "Epoch 1490, Loss: 0.5900675654411316\n",
      "Epoch 1500, Loss: 0.5897813439369202\n",
      "Epoch 1510, Loss: 0.5894967317581177\n",
      "Epoch 1520, Loss: 0.5892137885093689\n",
      "Epoch 1530, Loss: 0.5889323949813843\n",
      "Epoch 1540, Loss: 0.5886524319648743\n",
      "Epoch 1550, Loss: 0.588373601436615\n",
      "Epoch 1560, Loss: 0.5880960822105408\n",
      "Epoch 1570, Loss: 0.5878198742866516\n",
      "Epoch 1580, Loss: 0.5875452160835266\n",
      "Epoch 1590, Loss: 0.5872714519500732\n",
      "Epoch 1600, Loss: 0.5869988799095154\n",
      "Epoch 1610, Loss: 0.5867268443107605\n",
      "Epoch 1620, Loss: 0.5864554643630981\n",
      "Epoch 1630, Loss: 0.5861845016479492\n",
      "Epoch 1640, Loss: 0.585913896560669\n",
      "Epoch 1650, Loss: 0.585643470287323\n",
      "Epoch 1660, Loss: 0.585372805595398\n",
      "Epoch 1670, Loss: 0.5851016640663147\n",
      "Epoch 1680, Loss: 0.5848299264907837\n",
      "Epoch 1690, Loss: 0.5845586061477661\n",
      "Epoch 1700, Loss: 0.5842871069908142\n",
      "Epoch 1710, Loss: 0.5840120315551758\n",
      "Epoch 1720, Loss: 0.5837312340736389\n",
      "Epoch 1730, Loss: 0.5834429264068604\n",
      "Epoch 1740, Loss: 0.5831472873687744\n",
      "Epoch 1750, Loss: 0.5828459858894348\n",
      "Epoch 1760, Loss: 0.5825475454330444\n",
      "Epoch 1770, Loss: 0.5822564363479614\n",
      "Epoch 1780, Loss: 0.5819753408432007\n",
      "Epoch 1790, Loss: 0.5817015767097473\n",
      "Epoch 1800, Loss: 0.5814341306686401\n",
      "Epoch 1810, Loss: 0.5811725854873657\n",
      "Epoch 1820, Loss: 0.5809162855148315\n",
      "Epoch 1830, Loss: 0.5806625485420227\n",
      "Epoch 1840, Loss: 0.5804092884063721\n",
      "Epoch 1850, Loss: 0.5801557898521423\n",
      "Epoch 1860, Loss: 0.5799015164375305\n",
      "Epoch 1870, Loss: 0.5796464085578918\n",
      "Epoch 1880, Loss: 0.5793899297714233\n",
      "Epoch 1890, Loss: 0.5791314840316772\n",
      "Epoch 1900, Loss: 0.5788707137107849\n",
      "Epoch 1910, Loss: 0.5786093473434448\n",
      "Epoch 1920, Loss: 0.5783494710922241\n",
      "Epoch 1930, Loss: 0.5780916810035706\n",
      "Epoch 1940, Loss: 0.5778364539146423\n",
      "Epoch 1950, Loss: 0.5775825381278992\n",
      "Epoch 1960, Loss: 0.5773279666900635\n",
      "Epoch 1970, Loss: 0.577072024345398\n",
      "Epoch 1980, Loss: 0.5768143534660339\n",
      "Epoch 1990, Loss: 0.5765547156333923\n",
      "Epoch 2000, Loss: 0.5762936472892761\n",
      "Epoch 2010, Loss: 0.5760326385498047\n",
      "Epoch 2020, Loss: 0.575772225856781\n",
      "Epoch 2030, Loss: 0.575512707233429\n",
      "Epoch 2040, Loss: 0.5752542018890381\n",
      "Epoch 2050, Loss: 0.574996829032898\n",
      "Epoch 2060, Loss: 0.5747404098510742\n",
      "Epoch 2070, Loss: 0.5744843482971191\n",
      "Epoch 2080, Loss: 0.5742284655570984\n",
      "Epoch 2090, Loss: 0.5739728212356567\n",
      "Epoch 2100, Loss: 0.5737168192863464\n",
      "Epoch 2110, Loss: 0.5734606981277466\n",
      "Epoch 2120, Loss: 0.5732041001319885\n",
      "Epoch 2130, Loss: 0.5729470252990723\n",
      "Epoch 2140, Loss: 0.5726893544197083\n",
      "Epoch 2150, Loss: 0.5724311470985413\n",
      "Epoch 2160, Loss: 0.5721721649169922\n",
      "Epoch 2170, Loss: 0.5719123482704163\n",
      "Epoch 2180, Loss: 0.5716514587402344\n",
      "Epoch 2190, Loss: 0.5713895559310913\n",
      "Epoch 2200, Loss: 0.5711274743080139\n",
      "Epoch 2210, Loss: 0.5708658695220947\n",
      "Epoch 2220, Loss: 0.5706044435501099\n",
      "Epoch 2230, Loss: 0.5703434944152832\n",
      "Epoch 2240, Loss: 0.5700826644897461\n",
      "Epoch 2250, Loss: 0.5698220133781433\n",
      "Epoch 2260, Loss: 0.5695613622665405\n",
      "Epoch 2270, Loss: 0.569300651550293\n",
      "Epoch 2280, Loss: 0.5690397620201111\n",
      "Epoch 2290, Loss: 0.5687785744667053\n",
      "Epoch 2300, Loss: 0.5685171484947205\n",
      "Epoch 2310, Loss: 0.5682553052902222\n",
      "Epoch 2320, Loss: 0.5679930448532104\n",
      "Epoch 2330, Loss: 0.5677301287651062\n",
      "Epoch 2340, Loss: 0.5674669742584229\n",
      "Epoch 2350, Loss: 0.5672029256820679\n",
      "Epoch 2360, Loss: 0.5669382810592651\n",
      "Epoch 2370, Loss: 0.5666729211807251\n",
      "Epoch 2380, Loss: 0.5664066672325134\n",
      "Epoch 2390, Loss: 0.5661395192146301\n",
      "Epoch 2400, Loss: 0.5658714771270752\n",
      "Epoch 2410, Loss: 0.5656025409698486\n",
      "Epoch 2420, Loss: 0.5653325319290161\n",
      "Epoch 2430, Loss: 0.5650618076324463\n",
      "Epoch 2440, Loss: 0.5647897720336914\n",
      "Epoch 2450, Loss: 0.5645166635513306\n",
      "Epoch 2460, Loss: 0.5642423629760742\n",
      "Epoch 2470, Loss: 0.5639666318893433\n",
      "Epoch 2480, Loss: 0.563689649105072\n",
      "Epoch 2490, Loss: 0.5634108781814575\n",
      "Epoch 2500, Loss: 0.5631301999092102\n",
      "Epoch 2510, Loss: 0.5628474354743958\n",
      "Epoch 2520, Loss: 0.5625621676445007\n",
      "Epoch 2530, Loss: 0.5622739791870117\n",
      "Epoch 2540, Loss: 0.5619823932647705\n",
      "Epoch 2550, Loss: 0.5616864562034607\n",
      "Epoch 2560, Loss: 0.5613853931427002\n",
      "Epoch 2570, Loss: 0.561077892780304\n",
      "Epoch 2580, Loss: 0.5607622265815735\n",
      "Epoch 2590, Loss: 0.5604356527328491\n",
      "Epoch 2600, Loss: 0.5600947141647339\n",
      "Epoch 2610, Loss: 0.5597342252731323\n",
      "Epoch 2620, Loss: 0.5593459606170654\n",
      "Epoch 2630, Loss: 0.5589168071746826\n",
      "Epoch 2640, Loss: 0.5584304928779602\n",
      "Epoch 2650, Loss: 0.5579439401626587\n",
      "Epoch 2660, Loss: 0.5574727654457092\n",
      "Epoch 2670, Loss: 0.5569911599159241\n",
      "Epoch 2680, Loss: 0.5564890503883362\n",
      "Epoch 2690, Loss: 0.5559521913528442\n",
      "Epoch 2700, Loss: 0.5554091334342957\n",
      "Epoch 2710, Loss: 0.5548821091651917\n",
      "Epoch 2720, Loss: 0.5543751120567322\n",
      "Epoch 2730, Loss: 0.5538893938064575\n",
      "Epoch 2740, Loss: 0.5534327626228333\n",
      "Epoch 2750, Loss: 0.5530039668083191\n",
      "Epoch 2760, Loss: 0.5526003241539001\n",
      "Epoch 2770, Loss: 0.5522150993347168\n",
      "Epoch 2780, Loss: 0.5518422722816467\n",
      "Epoch 2790, Loss: 0.551478922367096\n",
      "Epoch 2800, Loss: 0.5511233806610107\n",
      "Epoch 2810, Loss: 0.5507742762565613\n",
      "Epoch 2820, Loss: 0.5504305362701416\n",
      "Epoch 2830, Loss: 0.5500911474227905\n",
      "Epoch 2840, Loss: 0.5497555136680603\n",
      "Epoch 2850, Loss: 0.5494228601455688\n",
      "Epoch 2860, Loss: 0.5490925312042236\n",
      "Epoch 2870, Loss: 0.5487642288208008\n",
      "Epoch 2880, Loss: 0.548437237739563\n",
      "Epoch 2890, Loss: 0.548111081123352\n",
      "Epoch 2900, Loss: 0.5477854013442993\n",
      "Epoch 2910, Loss: 0.5474610328674316\n",
      "Epoch 2920, Loss: 0.5471380949020386\n",
      "Epoch 2930, Loss: 0.5468167662620544\n",
      "Epoch 2940, Loss: 0.5464968085289001\n",
      "Epoch 2950, Loss: 0.546177864074707\n",
      "Epoch 2960, Loss: 0.5458598732948303\n",
      "Epoch 2970, Loss: 0.5455426573753357\n",
      "Epoch 2980, Loss: 0.5452263951301575\n",
      "Epoch 2990, Loss: 0.54491126537323\n",
      "Epoch 3000, Loss: 0.5445973873138428\n",
      "Epoch 3010, Loss: 0.5442846417427063\n",
      "Epoch 3020, Loss: 0.5439728498458862\n",
      "Epoch 3030, Loss: 0.5436620116233826\n",
      "Epoch 3040, Loss: 0.5433520078659058\n",
      "Epoch 3050, Loss: 0.5430428385734558\n",
      "Epoch 3060, Loss: 0.5427342653274536\n",
      "Epoch 3070, Loss: 0.5424262881278992\n",
      "Epoch 3080, Loss: 0.5421187877655029\n",
      "Epoch 3090, Loss: 0.5418117046356201\n",
      "Epoch 3100, Loss: 0.5415050983428955\n",
      "Epoch 3110, Loss: 0.5411989092826843\n",
      "Epoch 3120, Loss: 0.5408930778503418\n",
      "Epoch 3130, Loss: 0.5405876040458679\n",
      "Epoch 3140, Loss: 0.5402822494506836\n",
      "Epoch 3150, Loss: 0.5399771332740784\n",
      "Epoch 3160, Loss: 0.5396721363067627\n",
      "Epoch 3170, Loss: 0.5393673777580261\n",
      "Epoch 3180, Loss: 0.5390626192092896\n",
      "Epoch 3190, Loss: 0.5387579798698425\n",
      "Epoch 3200, Loss: 0.5384533405303955\n",
      "Epoch 3210, Loss: 0.5381487607955933\n",
      "Epoch 3220, Loss: 0.5378440022468567\n",
      "Epoch 3230, Loss: 0.5375391244888306\n",
      "Epoch 3240, Loss: 0.5372343063354492\n",
      "Epoch 3250, Loss: 0.5369291305541992\n",
      "Epoch 3260, Loss: 0.5366237759590149\n",
      "Epoch 3270, Loss: 0.5363182425498962\n",
      "Epoch 3280, Loss: 0.5360125303268433\n",
      "Epoch 3290, Loss: 0.5357063412666321\n",
      "Epoch 3300, Loss: 0.535399854183197\n",
      "Epoch 3310, Loss: 0.5350929498672485\n",
      "Epoch 3320, Loss: 0.5347855091094971\n",
      "Epoch 3330, Loss: 0.5344775319099426\n",
      "Epoch 3340, Loss: 0.5341689586639404\n",
      "Epoch 3350, Loss: 0.5338597297668457\n",
      "Epoch 3360, Loss: 0.5335498452186584\n",
      "Epoch 3370, Loss: 0.5332392454147339\n",
      "Epoch 3380, Loss: 0.5329278111457825\n",
      "Epoch 3390, Loss: 0.5326154828071594\n",
      "Epoch 3400, Loss: 0.5323023200035095\n",
      "Epoch 3410, Loss: 0.5319879651069641\n",
      "Epoch 3420, Loss: 0.531672477722168\n",
      "Epoch 3430, Loss: 0.5313557386398315\n",
      "Epoch 3440, Loss: 0.5310375094413757\n",
      "Epoch 3450, Loss: 0.5307179689407349\n",
      "Epoch 3460, Loss: 0.5303968787193298\n",
      "Epoch 3470, Loss: 0.5300742387771606\n",
      "Epoch 3480, Loss: 0.5297502875328064\n",
      "Epoch 3490, Loss: 0.5294252038002014\n",
      "Epoch 3500, Loss: 0.529098629951477\n",
      "Epoch 3510, Loss: 0.5287707448005676\n",
      "Epoch 3520, Loss: 0.5284410119056702\n",
      "Epoch 3530, Loss: 0.5281094908714294\n",
      "Epoch 3540, Loss: 0.527775764465332\n",
      "Epoch 3550, Loss: 0.5274395942687988\n",
      "Epoch 3560, Loss: 0.5271020531654358\n",
      "Epoch 3570, Loss: 0.526763916015625\n",
      "Epoch 3580, Loss: 0.5264253616333008\n",
      "Epoch 3590, Loss: 0.5260863304138184\n",
      "Epoch 3600, Loss: 0.5257470607757568\n",
      "Epoch 3610, Loss: 0.5254074931144714\n",
      "Epoch 3620, Loss: 0.5250676870346069\n",
      "Epoch 3630, Loss: 0.5247274041175842\n",
      "Epoch 3640, Loss: 0.5243868231773376\n",
      "Epoch 3650, Loss: 0.524046003818512\n",
      "Epoch 3660, Loss: 0.5237046480178833\n",
      "Epoch 3670, Loss: 0.5233628153800964\n",
      "Epoch 3680, Loss: 0.5230205655097961\n",
      "Epoch 3690, Loss: 0.5226778388023376\n",
      "Epoch 3700, Loss: 0.5223344564437866\n",
      "Epoch 3710, Loss: 0.5219906568527222\n",
      "Epoch 3720, Loss: 0.5216462016105652\n",
      "Epoch 3730, Loss: 0.52130126953125\n",
      "Epoch 3740, Loss: 0.520955502986908\n",
      "Epoch 3750, Loss: 0.5206092000007629\n",
      "Epoch 3760, Loss: 0.5202621221542358\n",
      "Epoch 3770, Loss: 0.5199145078659058\n",
      "Epoch 3780, Loss: 0.5195661187171936\n",
      "Epoch 3790, Loss: 0.5192168951034546\n",
      "Epoch 3800, Loss: 0.5188670754432678\n",
      "Epoch 3810, Loss: 0.5185163617134094\n",
      "Epoch 3820, Loss: 0.518164873123169\n",
      "Epoch 3830, Loss: 0.5178124308586121\n",
      "Epoch 3840, Loss: 0.5174591541290283\n",
      "Epoch 3850, Loss: 0.5171052813529968\n",
      "Epoch 3860, Loss: 0.5167505741119385\n",
      "Epoch 3870, Loss: 0.5163951516151428\n",
      "Epoch 3880, Loss: 0.5160389542579651\n",
      "Epoch 3890, Loss: 0.5156817436218262\n",
      "Epoch 3900, Loss: 0.5153237581253052\n",
      "Epoch 3910, Loss: 0.5149649977684021\n",
      "Epoch 3920, Loss: 0.5146052837371826\n",
      "Epoch 3930, Loss: 0.5142446160316467\n",
      "Epoch 3940, Loss: 0.5138829946517944\n",
      "Epoch 3950, Loss: 0.5135204195976257\n",
      "Epoch 3960, Loss: 0.5131569504737854\n",
      "Epoch 3970, Loss: 0.5127922892570496\n",
      "Epoch 3980, Loss: 0.5124267935752869\n",
      "Epoch 3990, Loss: 0.5120601654052734\n",
      "Epoch 4000, Loss: 0.511692225933075\n",
      "Epoch 4010, Loss: 0.5113233327865601\n",
      "Epoch 4020, Loss: 0.5109531283378601\n",
      "Epoch 4030, Loss: 0.5105815529823303\n",
      "Epoch 4040, Loss: 0.5102087259292603\n",
      "Epoch 4050, Loss: 0.5098345875740051\n",
      "Epoch 4060, Loss: 0.5094590783119202\n",
      "Epoch 4070, Loss: 0.5090820789337158\n",
      "Epoch 4080, Loss: 0.5087036490440369\n",
      "Epoch 4090, Loss: 0.5083235502243042\n",
      "Epoch 4100, Loss: 0.5079419612884521\n",
      "Epoch 4110, Loss: 0.5075585246086121\n",
      "Epoch 4120, Loss: 0.5071735978126526\n",
      "Epoch 4130, Loss: 0.5067875385284424\n",
      "Epoch 4140, Loss: 0.5064006447792053\n",
      "Epoch 4150, Loss: 0.5060129761695862\n",
      "Epoch 4160, Loss: 0.5056242346763611\n",
      "Epoch 4170, Loss: 0.5052342414855957\n",
      "Epoch 4180, Loss: 0.5048426389694214\n",
      "Epoch 4190, Loss: 0.5044507384300232\n",
      "Epoch 4200, Loss: 0.5040591955184937\n",
      "Epoch 4210, Loss: 0.5036681294441223\n",
      "Epoch 4220, Loss: 0.5032774209976196\n",
      "Epoch 4230, Loss: 0.502886950969696\n",
      "Epoch 4240, Loss: 0.502496600151062\n",
      "Epoch 4250, Loss: 0.5021061897277832\n",
      "Epoch 4260, Loss: 0.501715898513794\n",
      "Epoch 4270, Loss: 0.501325249671936\n",
      "Epoch 4280, Loss: 0.5009347200393677\n",
      "Epoch 4290, Loss: 0.5005443692207336\n",
      "Epoch 4300, Loss: 0.5001543760299683\n",
      "Epoch 4310, Loss: 0.49976450204849243\n",
      "Epoch 4320, Loss: 0.49937495589256287\n",
      "Epoch 4330, Loss: 0.49898552894592285\n",
      "Epoch 4340, Loss: 0.49859634041786194\n",
      "Epoch 4350, Loss: 0.4982071816921234\n",
      "Epoch 4360, Loss: 0.49781808257102966\n",
      "Epoch 4370, Loss: 0.4974290728569031\n",
      "Epoch 4380, Loss: 0.4970400333404541\n",
      "Epoch 4390, Loss: 0.4966510236263275\n",
      "Epoch 4400, Loss: 0.4962617754936218\n",
      "Epoch 4410, Loss: 0.495872437953949\n",
      "Epoch 4420, Loss: 0.4954829216003418\n",
      "Epoch 4430, Loss: 0.49509313702583313\n",
      "Epoch 4440, Loss: 0.4947029650211334\n",
      "Epoch 4450, Loss: 0.4943125247955322\n",
      "Epoch 4460, Loss: 0.49392175674438477\n",
      "Epoch 4470, Loss: 0.4935304522514343\n",
      "Epoch 4480, Loss: 0.4931386709213257\n",
      "Epoch 4490, Loss: 0.492746502161026\n",
      "Epoch 4500, Loss: 0.49235400557518005\n",
      "Epoch 4510, Loss: 0.49196135997772217\n",
      "Epoch 4520, Loss: 0.49156877398490906\n",
      "Epoch 4530, Loss: 0.4911760985851288\n",
      "Epoch 4540, Loss: 0.49078336358070374\n",
      "Epoch 4550, Loss: 0.4903905987739563\n",
      "Epoch 4560, Loss: 0.4899977743625641\n",
      "Epoch 4570, Loss: 0.4896048903465271\n",
      "Epoch 4580, Loss: 0.4892117977142334\n",
      "Epoch 4590, Loss: 0.4888186454772949\n",
      "Epoch 4600, Loss: 0.4884253740310669\n",
      "Epoch 4610, Loss: 0.48803186416625977\n",
      "Epoch 4620, Loss: 0.4876382350921631\n",
      "Epoch 4630, Loss: 0.48724454641342163\n",
      "Epoch 4640, Loss: 0.4868505001068115\n",
      "Epoch 4650, Loss: 0.48645639419555664\n",
      "Epoch 4660, Loss: 0.48606207966804504\n",
      "Epoch 4670, Loss: 0.4856675863265991\n",
      "Epoch 4680, Loss: 0.48527276515960693\n",
      "Epoch 4690, Loss: 0.48487794399261475\n",
      "Epoch 4700, Loss: 0.4844827353954315\n",
      "Epoch 4710, Loss: 0.48408740758895874\n",
      "Epoch 4720, Loss: 0.4836917519569397\n",
      "Epoch 4730, Loss: 0.4832960367202759\n",
      "Epoch 4740, Loss: 0.4828999638557434\n",
      "Epoch 4750, Loss: 0.48250362277030945\n",
      "Epoch 4760, Loss: 0.48210692405700684\n",
      "Epoch 4770, Loss: 0.48170995712280273\n",
      "Epoch 4780, Loss: 0.48131269216537476\n",
      "Epoch 4790, Loss: 0.4809150695800781\n",
      "Epoch 4800, Loss: 0.48051711916923523\n",
      "Epoch 4810, Loss: 0.48011890053749084\n",
      "Epoch 4820, Loss: 0.47972026467323303\n",
      "Epoch 4830, Loss: 0.47932133078575134\n",
      "Epoch 4840, Loss: 0.4789218306541443\n",
      "Epoch 4850, Loss: 0.47852209210395813\n",
      "Epoch 4860, Loss: 0.4781220555305481\n",
      "Epoch 4870, Loss: 0.4777217507362366\n",
      "Epoch 4880, Loss: 0.4773210287094116\n",
      "Epoch 4890, Loss: 0.4769201874732971\n",
      "Epoch 4900, Loss: 0.47651904821395874\n",
      "Epoch 4910, Loss: 0.4761175215244293\n",
      "Epoch 4920, Loss: 0.4757157862186432\n",
      "Epoch 4930, Loss: 0.47531378269195557\n",
      "Epoch 4940, Loss: 0.47491154074668884\n",
      "Epoch 4950, Loss: 0.4745091199874878\n",
      "Epoch 4960, Loss: 0.47410643100738525\n",
      "Epoch 4970, Loss: 0.473703533411026\n",
      "Epoch 4980, Loss: 0.4733002781867981\n",
      "Epoch 4990, Loss: 0.4728967547416687\n",
      "Epoch 5000, Loss: 0.47249290347099304\n",
      "Epoch 5010, Loss: 0.47208869457244873\n",
      "Epoch 5020, Loss: 0.4716840982437134\n",
      "Epoch 5030, Loss: 0.4712790548801422\n",
      "Epoch 5040, Loss: 0.47087371349334717\n",
      "Epoch 5050, Loss: 0.47046786546707153\n",
      "Epoch 5060, Loss: 0.4700617790222168\n",
      "Epoch 5070, Loss: 0.46965500712394714\n",
      "Epoch 5080, Loss: 0.4692477583885193\n",
      "Epoch 5090, Loss: 0.4688401222229004\n",
      "Epoch 5100, Loss: 0.4684317409992218\n",
      "Epoch 5110, Loss: 0.468022882938385\n",
      "Epoch 5120, Loss: 0.4676132798194885\n",
      "Epoch 5130, Loss: 0.46720290184020996\n",
      "Epoch 5140, Loss: 0.4667918384075165\n",
      "Epoch 5150, Loss: 0.4663802683353424\n",
      "Epoch 5160, Loss: 0.4659685790538788\n",
      "Epoch 5170, Loss: 0.4655567407608032\n",
      "Epoch 5180, Loss: 0.4651447534561157\n",
      "Epoch 5190, Loss: 0.46473246812820435\n",
      "Epoch 5200, Loss: 0.46432021260261536\n",
      "Epoch 5210, Loss: 0.46390774846076965\n",
      "Epoch 5220, Loss: 0.4634949862957001\n",
      "Epoch 5230, Loss: 0.4630821645259857\n",
      "Epoch 5240, Loss: 0.4626690149307251\n",
      "Epoch 5250, Loss: 0.46225565671920776\n",
      "Epoch 5260, Loss: 0.46184206008911133\n",
      "Epoch 5270, Loss: 0.46142804622650146\n",
      "Epoch 5280, Loss: 0.46101370453834534\n",
      "Epoch 5290, Loss: 0.46059900522232056\n",
      "Epoch 5300, Loss: 0.4601839482784271\n",
      "Epoch 5310, Loss: 0.4597685635089874\n",
      "Epoch 5320, Loss: 0.4593527317047119\n",
      "Epoch 5330, Loss: 0.4589364230632782\n",
      "Epoch 5340, Loss: 0.4585195481777191\n",
      "Epoch 5350, Loss: 0.458102285861969\n",
      "Epoch 5360, Loss: 0.45768439769744873\n",
      "Epoch 5370, Loss: 0.45726579427719116\n",
      "Epoch 5380, Loss: 0.45684656500816345\n",
      "Epoch 5390, Loss: 0.4564271867275238\n",
      "Epoch 5400, Loss: 0.4560082256793976\n",
      "Epoch 5410, Loss: 0.4555894732475281\n",
      "Epoch 5420, Loss: 0.4551708996295929\n",
      "Epoch 5430, Loss: 0.4547523856163025\n",
      "Epoch 5440, Loss: 0.45433416962623596\n",
      "Epoch 5450, Loss: 0.4539158046245575\n",
      "Epoch 5460, Loss: 0.4534975290298462\n",
      "Epoch 5470, Loss: 0.45307931303977966\n",
      "Epoch 5480, Loss: 0.45266103744506836\n",
      "Epoch 5490, Loss: 0.4522427022457123\n",
      "Epoch 5500, Loss: 0.4518243372440338\n",
      "Epoch 5510, Loss: 0.4514058828353882\n",
      "Epoch 5520, Loss: 0.4509872794151306\n",
      "Epoch 5530, Loss: 0.45056846737861633\n",
      "Epoch 5540, Loss: 0.4501494765281677\n",
      "Epoch 5550, Loss: 0.44973024725914\n",
      "Epoch 5560, Loss: 0.44931063055992126\n",
      "Epoch 5570, Loss: 0.44889092445373535\n",
      "Epoch 5580, Loss: 0.4484706521034241\n",
      "Epoch 5590, Loss: 0.44805005192756653\n",
      "Epoch 5600, Loss: 0.44762909412384033\n",
      "Epoch 5610, Loss: 0.4472077488899231\n",
      "Epoch 5620, Loss: 0.4467860758304596\n",
      "Epoch 5630, Loss: 0.4463638663291931\n",
      "Epoch 5640, Loss: 0.44594112038612366\n",
      "Epoch 5650, Loss: 0.4455176591873169\n",
      "Epoch 5660, Loss: 0.44509342312812805\n",
      "Epoch 5670, Loss: 0.4446682333946228\n",
      "Epoch 5680, Loss: 0.44424280524253845\n",
      "Epoch 5690, Loss: 0.44381728768348694\n",
      "Epoch 5700, Loss: 0.44339174032211304\n",
      "Epoch 5710, Loss: 0.44296595454216003\n",
      "Epoch 5720, Loss: 0.442539781332016\n",
      "Epoch 5730, Loss: 0.44211313128471375\n",
      "Epoch 5740, Loss: 0.4416859447956085\n",
      "Epoch 5750, Loss: 0.4412579834461212\n",
      "Epoch 5760, Loss: 0.440829336643219\n",
      "Epoch 5770, Loss: 0.44039982557296753\n",
      "Epoch 5780, Loss: 0.4399692714214325\n",
      "Epoch 5790, Loss: 0.4395374655723572\n",
      "Epoch 5800, Loss: 0.43910449743270874\n",
      "Epoch 5810, Loss: 0.438669890165329\n",
      "Epoch 5820, Loss: 0.4382336735725403\n",
      "Epoch 5830, Loss: 0.4377953112125397\n",
      "Epoch 5840, Loss: 0.4373544454574585\n",
      "Epoch 5850, Loss: 0.4369106888771057\n",
      "Epoch 5860, Loss: 0.4364634156227112\n",
      "Epoch 5870, Loss: 0.4360121190547943\n",
      "Epoch 5880, Loss: 0.43555593490600586\n",
      "Epoch 5890, Loss: 0.4350939393043518\n",
      "Epoch 5900, Loss: 0.4346248209476471\n",
      "Epoch 5910, Loss: 0.4341479539871216\n",
      "Epoch 5920, Loss: 0.4336714446544647\n",
      "Epoch 5930, Loss: 0.4332038164138794\n",
      "Epoch 5940, Loss: 0.43274396657943726\n",
      "Epoch 5950, Loss: 0.43228986859321594\n",
      "Epoch 5960, Loss: 0.4318399727344513\n",
      "Epoch 5970, Loss: 0.43139374256134033\n",
      "Epoch 5980, Loss: 0.4309503138065338\n",
      "Epoch 5990, Loss: 0.4305092394351959\n",
      "Epoch 6000, Loss: 0.43007031083106995\n",
      "Epoch 6010, Loss: 0.4296330213546753\n",
      "Epoch 6020, Loss: 0.42919740080833435\n",
      "Epoch 6030, Loss: 0.42876318097114563\n",
      "Epoch 6040, Loss: 0.4283301532268524\n",
      "Epoch 6050, Loss: 0.42789825797080994\n",
      "Epoch 6060, Loss: 0.42746758460998535\n",
      "Epoch 6070, Loss: 0.42703768610954285\n",
      "Epoch 6080, Loss: 0.426608681678772\n",
      "Epoch 6090, Loss: 0.42618057131767273\n",
      "Epoch 6100, Loss: 0.42575305700302124\n",
      "Epoch 6110, Loss: 0.42532631754875183\n",
      "Epoch 6120, Loss: 0.4249002933502197\n",
      "Epoch 6130, Loss: 0.4244745373725891\n",
      "Epoch 6140, Loss: 0.4240494668483734\n",
      "Epoch 6150, Loss: 0.4236249327659607\n",
      "Epoch 6160, Loss: 0.42320069670677185\n",
      "Epoch 6170, Loss: 0.42277681827545166\n",
      "Epoch 6180, Loss: 0.4223534166812897\n",
      "Epoch 6190, Loss: 0.42193031311035156\n",
      "Epoch 6200, Loss: 0.4215075373649597\n",
      "Epoch 6210, Loss: 0.421085000038147\n",
      "Epoch 6220, Loss: 0.42066261172294617\n",
      "Epoch 6230, Loss: 0.4202406704425812\n",
      "Epoch 6240, Loss: 0.4198187291622162\n",
      "Epoch 6250, Loss: 0.4193970859050751\n",
      "Epoch 6260, Loss: 0.41897574067115784\n",
      "Epoch 6270, Loss: 0.4185543954372406\n",
      "Epoch 6280, Loss: 0.4181331992149353\n",
      "Epoch 6290, Loss: 0.41771215200424194\n",
      "Epoch 6300, Loss: 0.4172912836074829\n",
      "Epoch 6310, Loss: 0.4168703854084015\n",
      "Epoch 6320, Loss: 0.4164493978023529\n",
      "Epoch 6330, Loss: 0.4160284698009491\n",
      "Epoch 6340, Loss: 0.4156074523925781\n",
      "Epoch 6350, Loss: 0.41518616676330566\n",
      "Epoch 6360, Loss: 0.4147648811340332\n",
      "Epoch 6370, Loss: 0.41434356570243835\n",
      "Epoch 6380, Loss: 0.4139222502708435\n",
      "Epoch 6390, Loss: 0.4135008156299591\n",
      "Epoch 6400, Loss: 0.4130791425704956\n",
      "Epoch 6410, Loss: 0.41265714168548584\n",
      "Epoch 6420, Loss: 0.41223466396331787\n",
      "Epoch 6430, Loss: 0.41181156039237976\n",
      "Epoch 6440, Loss: 0.41138729453086853\n",
      "Epoch 6450, Loss: 0.41096165776252747\n",
      "Epoch 6460, Loss: 0.4105345904827118\n",
      "Epoch 6470, Loss: 0.41010814905166626\n",
      "Epoch 6480, Loss: 0.4096825420856476\n",
      "Epoch 6490, Loss: 0.40925779938697815\n",
      "Epoch 6500, Loss: 0.408833771944046\n",
      "Epoch 6510, Loss: 0.40841013193130493\n",
      "Epoch 6520, Loss: 0.40798693895339966\n",
      "Epoch 6530, Loss: 0.4075641632080078\n",
      "Epoch 6540, Loss: 0.4071415364742279\n",
      "Epoch 6550, Loss: 0.4067193865776062\n",
      "Epoch 6560, Loss: 0.40629735589027405\n",
      "Epoch 6570, Loss: 0.4058755934238434\n",
      "Epoch 6580, Loss: 0.4054538905620575\n",
      "Epoch 6590, Loss: 0.4050324559211731\n",
      "Epoch 6600, Loss: 0.40461093187332153\n",
      "Epoch 6610, Loss: 0.40418946743011475\n",
      "Epoch 6620, Loss: 0.40376797318458557\n",
      "Epoch 6630, Loss: 0.4033462703227997\n",
      "Epoch 6640, Loss: 0.4029243290424347\n",
      "Epoch 6650, Loss: 0.4025019705295563\n",
      "Epoch 6660, Loss: 0.40207910537719727\n",
      "Epoch 6670, Loss: 0.40165576338768005\n",
      "Epoch 6680, Loss: 0.401231586933136\n",
      "Epoch 6690, Loss: 0.4008064270019531\n",
      "Epoch 6700, Loss: 0.40038007497787476\n",
      "Epoch 6710, Loss: 0.39995241165161133\n",
      "Epoch 6720, Loss: 0.3995231091976166\n",
      "Epoch 6730, Loss: 0.39909180998802185\n",
      "Epoch 6740, Loss: 0.3986581861972809\n",
      "Epoch 6750, Loss: 0.3982217311859131\n",
      "Epoch 6760, Loss: 0.39778217673301697\n",
      "Epoch 6770, Loss: 0.39733850955963135\n",
      "Epoch 6780, Loss: 0.3968902826309204\n",
      "Epoch 6790, Loss: 0.3964371681213379\n",
      "Epoch 6800, Loss: 0.39597809314727783\n",
      "Epoch 6810, Loss: 0.3955116271972656\n",
      "Epoch 6820, Loss: 0.39503610134124756\n",
      "Epoch 6830, Loss: 0.39454948902130127\n",
      "Epoch 6840, Loss: 0.3940536677837372\n",
      "Epoch 6850, Loss: 0.3935506343841553\n",
      "Epoch 6860, Loss: 0.39304518699645996\n",
      "Epoch 6870, Loss: 0.39254096150398254\n",
      "Epoch 6880, Loss: 0.39203816652297974\n",
      "Epoch 6890, Loss: 0.39153963327407837\n",
      "Epoch 6900, Loss: 0.39104732871055603\n",
      "Epoch 6910, Loss: 0.39056071639060974\n",
      "Epoch 6920, Loss: 0.3900794982910156\n",
      "Epoch 6930, Loss: 0.3896031379699707\n",
      "Epoch 6940, Loss: 0.3891310393810272\n",
      "Epoch 6950, Loss: 0.38866302371025085\n",
      "Epoch 6960, Loss: 0.38819870352745056\n",
      "Epoch 6970, Loss: 0.38773754239082336\n",
      "Epoch 6980, Loss: 0.38727933168411255\n",
      "Epoch 6990, Loss: 0.3868234157562256\n",
      "Epoch 7000, Loss: 0.3863692581653595\n",
      "Epoch 7010, Loss: 0.3859161138534546\n",
      "Epoch 7020, Loss: 0.3854631185531616\n",
      "Epoch 7030, Loss: 0.38500872254371643\n",
      "Epoch 7040, Loss: 0.38455089926719666\n",
      "Epoch 7050, Loss: 0.38408684730529785\n",
      "Epoch 7060, Loss: 0.3836231529712677\n",
      "Epoch 7070, Loss: 0.3831644356250763\n",
      "Epoch 7080, Loss: 0.38271060585975647\n",
      "Epoch 7090, Loss: 0.3822607696056366\n",
      "Epoch 7100, Loss: 0.3818145990371704\n",
      "Epoch 7110, Loss: 0.38137176632881165\n",
      "Epoch 7120, Loss: 0.3809320330619812\n",
      "Epoch 7130, Loss: 0.38049519062042236\n",
      "Epoch 7140, Loss: 0.3800611197948456\n",
      "Epoch 7150, Loss: 0.3796294033527374\n",
      "Epoch 7160, Loss: 0.3791998624801636\n",
      "Epoch 7170, Loss: 0.37877240777015686\n",
      "Epoch 7180, Loss: 0.37834683060646057\n",
      "Epoch 7190, Loss: 0.37792304158210754\n",
      "Epoch 7200, Loss: 0.37750089168548584\n",
      "Epoch 7210, Loss: 0.3770802319049835\n",
      "Epoch 7220, Loss: 0.37666112184524536\n",
      "Epoch 7230, Loss: 0.3762432336807251\n",
      "Epoch 7240, Loss: 0.37582653760910034\n",
      "Epoch 7250, Loss: 0.37541109323501587\n",
      "Epoch 7260, Loss: 0.37499678134918213\n",
      "Epoch 7270, Loss: 0.37458354234695435\n",
      "Epoch 7280, Loss: 0.37417125701904297\n",
      "Epoch 7290, Loss: 0.3737598657608032\n",
      "Epoch 7300, Loss: 0.37334945797920227\n",
      "Epoch 7310, Loss: 0.3729400038719177\n",
      "Epoch 7320, Loss: 0.37253138422966003\n",
      "Epoch 7330, Loss: 0.3721235394477844\n",
      "Epoch 7340, Loss: 0.3717162311077118\n",
      "Epoch 7350, Loss: 0.3713095784187317\n",
      "Epoch 7360, Loss: 0.3709033727645874\n",
      "Epoch 7370, Loss: 0.3704976737499237\n",
      "Epoch 7380, Loss: 0.3700920045375824\n",
      "Epoch 7390, Loss: 0.36968645453453064\n",
      "Epoch 7400, Loss: 0.3692808449268341\n",
      "Epoch 7410, Loss: 0.36887481808662415\n",
      "Epoch 7420, Loss: 0.3684685528278351\n",
      "Epoch 7430, Loss: 0.36806416511535645\n",
      "Epoch 7440, Loss: 0.36766132712364197\n",
      "Epoch 7450, Loss: 0.36725983023643494\n",
      "Epoch 7460, Loss: 0.36685895919799805\n",
      "Epoch 7470, Loss: 0.3664590120315552\n",
      "Epoch 7480, Loss: 0.3660602271556854\n",
      "Epoch 7490, Loss: 0.3656623363494873\n",
      "Epoch 7500, Loss: 0.365265429019928\n",
      "Epoch 7510, Loss: 0.36486929655075073\n",
      "Epoch 7520, Loss: 0.36447423696517944\n",
      "Epoch 7530, Loss: 0.3640800416469574\n",
      "Epoch 7540, Loss: 0.3636869192123413\n",
      "Epoch 7550, Loss: 0.3632945120334625\n",
      "Epoch 7560, Loss: 0.36290305852890015\n",
      "Epoch 7570, Loss: 0.3625124394893646\n",
      "Epoch 7580, Loss: 0.36212268471717834\n",
      "Epoch 7590, Loss: 0.3617335855960846\n",
      "Epoch 7600, Loss: 0.3613453805446625\n",
      "Epoch 7610, Loss: 0.3609578311443329\n",
      "Epoch 7620, Loss: 0.3605709969997406\n",
      "Epoch 7630, Loss: 0.3601849377155304\n",
      "Epoch 7640, Loss: 0.35979950428009033\n",
      "Epoch 7650, Loss: 0.3594147861003876\n",
      "Epoch 7660, Loss: 0.3590308725833893\n",
      "Epoch 7670, Loss: 0.3586474061012268\n",
      "Epoch 7680, Loss: 0.3582647740840912\n",
      "Epoch 7690, Loss: 0.35788264870643616\n",
      "Epoch 7700, Loss: 0.35750120878219604\n",
      "Epoch 7710, Loss: 0.35712021589279175\n",
      "Epoch 7720, Loss: 0.3567397892475128\n",
      "Epoch 7730, Loss: 0.3563600182533264\n",
      "Epoch 7740, Loss: 0.35598087310791016\n",
      "Epoch 7750, Loss: 0.3556024134159088\n",
      "Epoch 7760, Loss: 0.3552245497703552\n",
      "Epoch 7770, Loss: 0.35484710335731506\n",
      "Epoch 7780, Loss: 0.35447025299072266\n",
      "Epoch 7790, Loss: 0.3540937006473541\n",
      "Epoch 7800, Loss: 0.3537176549434662\n",
      "Epoch 7810, Loss: 0.35334181785583496\n",
      "Epoch 7820, Loss: 0.3529660999774933\n",
      "Epoch 7830, Loss: 0.3525904715061188\n",
      "Epoch 7840, Loss: 0.35221466422080994\n",
      "Epoch 7850, Loss: 0.35183849930763245\n",
      "Epoch 7860, Loss: 0.35146185755729675\n",
      "Epoch 7870, Loss: 0.3510842025279999\n",
      "Epoch 7880, Loss: 0.3507048785686493\n",
      "Epoch 7890, Loss: 0.35032376646995544\n",
      "Epoch 7900, Loss: 0.34993985295295715\n",
      "Epoch 7910, Loss: 0.3495526909828186\n",
      "Epoch 7920, Loss: 0.34916138648986816\n",
      "Epoch 7930, Loss: 0.3487641513347626\n",
      "Epoch 7940, Loss: 0.34835851192474365\n",
      "Epoch 7950, Loss: 0.3479424715042114\n",
      "Epoch 7960, Loss: 0.3475133776664734\n",
      "Epoch 7970, Loss: 0.3470682203769684\n",
      "Epoch 7980, Loss: 0.3466024696826935\n",
      "Epoch 7990, Loss: 0.3461408317089081\n",
      "Epoch 8000, Loss: 0.345699280500412\n",
      "Epoch 8010, Loss: 0.3452754020690918\n",
      "Epoch 8020, Loss: 0.3448622524738312\n",
      "Epoch 8030, Loss: 0.3444569408893585\n",
      "Epoch 8040, Loss: 0.3440585732460022\n",
      "Epoch 8050, Loss: 0.34366559982299805\n",
      "Epoch 8060, Loss: 0.3432770371437073\n",
      "Epoch 8070, Loss: 0.3428921699523926\n",
      "Epoch 8080, Loss: 0.34251052141189575\n",
      "Epoch 8090, Loss: 0.34213197231292725\n",
      "Epoch 8100, Loss: 0.3417559266090393\n",
      "Epoch 8110, Loss: 0.34138232469558716\n",
      "Epoch 8120, Loss: 0.3410108983516693\n",
      "Epoch 8130, Loss: 0.3406415283679962\n",
      "Epoch 8140, Loss: 0.34027421474456787\n",
      "Epoch 8150, Loss: 0.3399084806442261\n",
      "Epoch 8160, Loss: 0.33954453468322754\n",
      "Epoch 8170, Loss: 0.3391821086406708\n",
      "Epoch 8180, Loss: 0.3388212323188782\n",
      "Epoch 8190, Loss: 0.33846181631088257\n",
      "Epoch 8200, Loss: 0.338103711605072\n",
      "Epoch 8210, Loss: 0.3377469778060913\n",
      "Epoch 8220, Loss: 0.3373914957046509\n",
      "Epoch 8230, Loss: 0.3370371460914612\n",
      "Epoch 8240, Loss: 0.3366841673851013\n",
      "Epoch 8250, Loss: 0.3363323211669922\n",
      "Epoch 8260, Loss: 0.33598145842552185\n",
      "Epoch 8270, Loss: 0.3356318473815918\n",
      "Epoch 8280, Loss: 0.3352832496166229\n",
      "Epoch 8290, Loss: 0.3349357843399048\n",
      "Epoch 8300, Loss: 0.3345891833305359\n",
      "Epoch 8310, Loss: 0.33424368500709534\n",
      "Epoch 8320, Loss: 0.3338993191719055\n",
      "Epoch 8330, Loss: 0.33355584740638733\n",
      "Epoch 8340, Loss: 0.33321353793144226\n",
      "Epoch 8350, Loss: 0.3328721821308136\n",
      "Epoch 8360, Loss: 0.3325318694114685\n",
      "Epoch 8370, Loss: 0.3321923613548279\n",
      "Epoch 8380, Loss: 0.3318540155887604\n",
      "Epoch 8390, Loss: 0.3315165042877197\n",
      "Epoch 8400, Loss: 0.33117976784706116\n",
      "Epoch 8410, Loss: 0.33084407448768616\n",
      "Epoch 8420, Loss: 0.3305090367794037\n",
      "Epoch 8430, Loss: 0.33017486333847046\n",
      "Epoch 8440, Loss: 0.32984158396720886\n",
      "Epoch 8450, Loss: 0.3295092284679413\n",
      "Epoch 8460, Loss: 0.329177588224411\n",
      "Epoch 8470, Loss: 0.3288467824459076\n",
      "Epoch 8480, Loss: 0.3285169303417206\n",
      "Epoch 8490, Loss: 0.3281877040863037\n",
      "Epoch 8500, Loss: 0.32785937190055847\n",
      "Epoch 8510, Loss: 0.3275319039821625\n",
      "Epoch 8520, Loss: 0.3272050619125366\n",
      "Epoch 8530, Loss: 0.32687908411026\n",
      "Epoch 8540, Loss: 0.3265538513660431\n",
      "Epoch 8550, Loss: 0.326229453086853\n",
      "Epoch 8560, Loss: 0.32590562105178833\n",
      "Epoch 8570, Loss: 0.3255825340747833\n",
      "Epoch 8580, Loss: 0.3252602815628052\n",
      "Epoch 8590, Loss: 0.32493856549263\n",
      "Epoch 8600, Loss: 0.3246176838874817\n",
      "Epoch 8610, Loss: 0.32429754734039307\n",
      "Epoch 8620, Loss: 0.3239779472351074\n",
      "Epoch 8630, Loss: 0.323659211397171\n",
      "Epoch 8640, Loss: 0.32334110140800476\n",
      "Epoch 8650, Loss: 0.32302361726760864\n",
      "Epoch 8660, Loss: 0.32270678877830505\n",
      "Epoch 8670, Loss: 0.3223905861377716\n",
      "Epoch 8680, Loss: 0.3220750391483307\n",
      "Epoch 8690, Loss: 0.32176029682159424\n",
      "Epoch 8700, Loss: 0.32144594192504883\n",
      "Epoch 8710, Loss: 0.32113248109817505\n",
      "Epoch 8720, Loss: 0.32081952691078186\n",
      "Epoch 8730, Loss: 0.32050710916519165\n",
      "Epoch 8740, Loss: 0.32019543647766113\n",
      "Epoch 8750, Loss: 0.31988435983657837\n",
      "Epoch 8760, Loss: 0.3195738196372986\n",
      "Epoch 8770, Loss: 0.31926384568214417\n",
      "Epoch 8780, Loss: 0.31895455718040466\n",
      "Epoch 8790, Loss: 0.31864580512046814\n",
      "Epoch 8800, Loss: 0.31833767890930176\n",
      "Epoch 8810, Loss: 0.31803008913993835\n",
      "Epoch 8820, Loss: 0.31772303581237793\n",
      "Epoch 8830, Loss: 0.31741654872894287\n",
      "Epoch 8840, Loss: 0.3171106278896332\n",
      "Epoch 8850, Loss: 0.31680524349212646\n",
      "Epoch 8860, Loss: 0.3165005147457123\n",
      "Epoch 8870, Loss: 0.3161962330341339\n",
      "Epoch 8880, Loss: 0.3158925771713257\n",
      "Epoch 8890, Loss: 0.31558936834335327\n",
      "Epoch 8900, Loss: 0.31528666615486145\n",
      "Epoch 8910, Loss: 0.314984530210495\n",
      "Epoch 8920, Loss: 0.3146830201148987\n",
      "Epoch 8930, Loss: 0.3143819570541382\n",
      "Epoch 8940, Loss: 0.3140813410282135\n",
      "Epoch 8950, Loss: 0.3137813210487366\n",
      "Epoch 8960, Loss: 0.313481867313385\n",
      "Epoch 8970, Loss: 0.31318289041519165\n",
      "Epoch 8980, Loss: 0.3128843307495117\n",
      "Epoch 8990, Loss: 0.31258630752563477\n",
      "Epoch 9000, Loss: 0.3122888207435608\n",
      "Epoch 9010, Loss: 0.3119916617870331\n",
      "Epoch 9020, Loss: 0.31169524788856506\n",
      "Epoch 9030, Loss: 0.3113992214202881\n",
      "Epoch 9040, Loss: 0.31110355257987976\n",
      "Epoch 9050, Loss: 0.3108084499835968\n",
      "Epoch 9060, Loss: 0.3105134963989258\n",
      "Epoch 9070, Loss: 0.31021812558174133\n",
      "Epoch 9080, Loss: 0.30991920828819275\n",
      "Epoch 9090, Loss: 0.30960917472839355\n",
      "Epoch 9100, Loss: 0.3092702627182007\n",
      "Epoch 9110, Loss: 0.3088822364807129\n",
      "Epoch 9120, Loss: 0.3084399402141571\n",
      "Epoch 9130, Loss: 0.30798178911209106\n",
      "Epoch 9140, Loss: 0.3075504004955292\n",
      "Epoch 9150, Loss: 0.30714449286460876\n",
      "Epoch 9160, Loss: 0.3067580759525299\n",
      "Epoch 9170, Loss: 0.30638641119003296\n",
      "Epoch 9180, Loss: 0.306026428937912\n",
      "Epoch 9190, Loss: 0.3056758940219879\n",
      "Epoch 9200, Loss: 0.30533304810523987\n",
      "Epoch 9210, Loss: 0.3049967288970947\n",
      "Epoch 9220, Loss: 0.3046656548976898\n",
      "Epoch 9230, Loss: 0.3043389916419983\n",
      "Epoch 9240, Loss: 0.3040161728858948\n",
      "Epoch 9250, Loss: 0.30369672179222107\n",
      "Epoch 9260, Loss: 0.30337998270988464\n",
      "Epoch 9270, Loss: 0.30306556820869446\n",
      "Epoch 9280, Loss: 0.3027532994747162\n",
      "Epoch 9290, Loss: 0.3024429380893707\n",
      "Epoch 9300, Loss: 0.30213403701782227\n",
      "Epoch 9310, Loss: 0.30182671546936035\n",
      "Epoch 9320, Loss: 0.3015206456184387\n",
      "Epoch 9330, Loss: 0.30121558904647827\n",
      "Epoch 9340, Loss: 0.30091166496276855\n",
      "Epoch 9350, Loss: 0.3006086051464081\n",
      "Epoch 9360, Loss: 0.3003064692020416\n",
      "Epoch 9370, Loss: 0.30000507831573486\n",
      "Epoch 9380, Loss: 0.2997046113014221\n",
      "Epoch 9390, Loss: 0.2994046211242676\n",
      "Epoch 9400, Loss: 0.2991054654121399\n",
      "Epoch 9410, Loss: 0.2988068163394928\n",
      "Epoch 9420, Loss: 0.29850897192955017\n",
      "Epoch 9430, Loss: 0.2982119619846344\n",
      "Epoch 9440, Loss: 0.2979157269001007\n",
      "Epoch 9450, Loss: 0.29762008786201477\n",
      "Epoch 9460, Loss: 0.2973250150680542\n",
      "Epoch 9470, Loss: 0.29703062772750854\n",
      "Epoch 9480, Loss: 0.29673683643341064\n",
      "Epoch 9490, Loss: 0.29644355177879333\n",
      "Epoch 9500, Loss: 0.29615068435668945\n",
      "Epoch 9510, Loss: 0.2958584427833557\n",
      "Epoch 9520, Loss: 0.29556652903556824\n",
      "Epoch 9530, Loss: 0.2952750325202942\n",
      "Epoch 9540, Loss: 0.29498428106307983\n",
      "Epoch 9550, Loss: 0.2946937680244446\n",
      "Epoch 9560, Loss: 0.2944037616252899\n",
      "Epoch 9570, Loss: 0.2941141724586487\n",
      "Epoch 9580, Loss: 0.2938250005245209\n",
      "Epoch 9590, Loss: 0.2935362458229065\n",
      "Epoch 9600, Loss: 0.2932479679584503\n",
      "Epoch 9610, Loss: 0.2929600179195404\n",
      "Epoch 9620, Loss: 0.29267245531082153\n",
      "Epoch 9630, Loss: 0.2923853099346161\n",
      "Epoch 9640, Loss: 0.2920984625816345\n",
      "Epoch 9650, Loss: 0.29181209206581116\n",
      "Epoch 9660, Loss: 0.29152604937553406\n",
      "Epoch 9670, Loss: 0.291240394115448\n",
      "Epoch 9680, Loss: 0.29095524549484253\n",
      "Epoch 9690, Loss: 0.2906704545021057\n",
      "Epoch 9700, Loss: 0.2903863489627838\n",
      "Epoch 9710, Loss: 0.2901023030281067\n",
      "Epoch 9720, Loss: 0.2898189425468445\n",
      "Epoch 9730, Loss: 0.2895359992980957\n",
      "Epoch 9740, Loss: 0.2892533540725708\n",
      "Epoch 9750, Loss: 0.28897109627723694\n",
      "Epoch 9760, Loss: 0.28868916630744934\n",
      "Epoch 9770, Loss: 0.2884076237678528\n",
      "Epoch 9780, Loss: 0.288126677274704\n",
      "Epoch 9790, Loss: 0.28784602880477905\n",
      "Epoch 9800, Loss: 0.2875656187534332\n",
      "Epoch 9810, Loss: 0.28728553652763367\n",
      "Epoch 9820, Loss: 0.28700587153434753\n",
      "Epoch 9830, Loss: 0.2867263853549957\n",
      "Epoch 9840, Loss: 0.2864474356174469\n",
      "Epoch 9850, Loss: 0.2861686646938324\n",
      "Epoch 9860, Loss: 0.2858901619911194\n",
      "Epoch 9870, Loss: 0.28561198711395264\n",
      "Epoch 9880, Loss: 0.2853340804576874\n",
      "Epoch 9890, Loss: 0.2850562632083893\n",
      "Epoch 9900, Loss: 0.2847789525985718\n",
      "Epoch 9910, Loss: 0.2845016121864319\n",
      "Epoch 9920, Loss: 0.2842246890068054\n",
      "Epoch 9930, Loss: 0.2839479148387909\n",
      "Epoch 9940, Loss: 0.28367137908935547\n",
      "Epoch 9950, Loss: 0.283394992351532\n",
      "Epoch 9960, Loss: 0.28311896324157715\n",
      "Epoch 9970, Loss: 0.2828430235385895\n",
      "Epoch 9980, Loss: 0.2825671136379242\n",
      "Epoch 9990, Loss: 0.2822912633419037\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    val_logits = out[data['transaction'].val_mask]\n",
    "    val_preds = torch.argmax(val_logits, dim=1)\n",
    "    val_labels = data['transaction'].y[data['transaction'].val_mask]\n",
    "print(val_labels.bincount())\n",
    "f1 = f1_score(val_labels.cpu(), val_preds.cpu(), average='binary')\n",
    "accuracy = accuracy_score(val_labels.cpu(), val_preds.cpu())\n",
    "conf_matrix = confusion_matrix(val_labels.cpu(), val_preds.cpu())\n",
    "\n",
    "print(f\"Validation F1 Score: {f1:.4f}\")\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "afR9vhZmaT2i",
    "outputId": "6768f266-1dd3-4834-e33f-446dbce6e442",
    "ExecuteTime": {
     "end_time": "2024-11-29T17:59:18.767955Z",
     "start_time": "2024-11-29T17:59:18.758600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([34, 36])\n",
      "Validation F1 Score: 0.5938\n",
      "Validation Accuracy: 0.6286\n",
      "Confusion Matrix:\n",
      "[[25  9]\n",
      " [17 19]]\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ]
}
